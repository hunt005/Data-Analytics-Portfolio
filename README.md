# Data Analytics Portfolio

## About
Hi, my name is Hunter Wilson. I am currently attaining a Masters of Science in Business Analytics from The University of Alabama Huntsville (expected graduation in May 2024).

The majority of my work is in Python and R. The major focus of my projects and coursework involved predictive analytics and machine learning. Specific algorithms include regression, clustering, CART, Random Forest, Na√Øve Bayes, SVM, various ensemble methods and text mining. Each of the examples below contain a file and description which showcases a homework, project or exam assignment where a certain machine learning or data analytics technique was used.

## Table of Contents
[**About**](#about)

[**Python**](#python)  
- [Natural Language Processing](#natural-language-processing)

## Python

### Natural Language Processing
**Skills**: Doc2Vec, NLTK, cosine similarity, bag of words   
**Code**: [natural_language_processing.ipynb](./Python%20Projects/natural_language_processing.ipynb)   
**Description**: This is a modified version of the code for the natural language processing capstone project. This version compares scientific articles (focusing on a specific aspect of the kidney) to 8 general kidney physiology statements. Each article is broken down into individual paragraphs and common stop words are removed to provide more precise results. For each of the 8 general statement, the resulting top 5 most similar paragraphs, cosine similarity scores, and document names are provided and outputted to the Google Drive as a CSV. This provides a good example of the domain flexibility that natural language processing provides; from creating capability matrices for large businesses to analyzing the insights of renal studies in the scientific field.      





## R

### Malicious Webpages Case Study  
**Skills**: randomForest, feature selection, Naive Bayes, imbalanced classification, hyperparameter tuning, missing data, ggplot   
**Code**: [Malicious_Webpages_Case_Study.R](./R%20Projects/Malicious_Webpages_Case_Study.R)      
**Description**: The goal of this exam was to create an algorithm which can predict the status of a new website for a private security organization based on 36,623 training data observations. The overall process started with handling the missing data and observing trends using ggplot. Random Forest and naive bayes models were trained for each modification to the data set (adding new features, feature selection, and imbalanced classification on the independent variable). Finally, hyperparameter tuning helped create the final model recommendation. The assignment also factored in that from a business perspective, the worst outcome is predicting that a website is good, but in actuality, the website is bad. This required adjusting the algorithm to reduce the number of false positives and finding the proper balance between overall accuracy and precision.     
